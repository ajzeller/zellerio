---
layout: default
title: Andrew Zeller | VocalFocals
permalink: /vocalfocals
project_title: Wearable IOT Text Recognition
id: "vocalfocals"
color: vocal-focals
live_url: https://ajzeller.github.io/vocal_focals_web/
image_1: vocalfocals.jpg
image_2: vocalfocals-2.jpg
image_3: vocalfocals-4.jpg
image_4: vocalfocals-banner.jpg

source_type: Github
source_icon: github
source_url: https://github.com/ajzeller/vocal_focals

---


{% include components/project-header.html %}

<p class="project-intro">
        A wearable device that recognizes printed text, logos, and object labels in the environment and relays this to the wearer over audio.
</p>

{% include components/project-details.html %}

<div class="container--project-text">
    <div class="project-text-body">
        <div class="container--built-with">
            <h3>Built with:</h3>
            {% include components/tags/python.html %}
            {% include components/tags/jekyll.html %}
            {% include components/tags/sass.html %}
            {% include components/tags/solidworks.html %}
        </div>

        <h3>Overview</h3>

        <p>
            VocalFocals was my senior design project at the University of Alabama. 
            I served as the technical manager for the project and did all software development. 
            The goal of the project was to develop a proof-of-concept device that could assist 
            visually impaired individuals with navigating around campus. As a team of six mechanical engineers, 
            this was a particularly challenging project as the core of the problem was in solving the software and computing architecture. 
            However it ended up being an incredibly rewarding project as we developed a working prototype and won the top senior design project 
            of our cohort, and learning a ton throughout the project.
        </p>

        <h3>Development/Outcome</h3>
            
        <p>
            Take a look at our <a href="https://drive.google.com/file/d/1lZdkG7cTQnJPl02RO5jd5BUpiuGzbP_D/view?usp=sharing">final presentation poster</a>
            for a detailed overview of the project. By the end of the project, we completed a functional, wearable prototype. Our final proof-of-c oncept could recognize text,
            automatically detect other languages and translate to English, detect object labels and brand logos, and relay all of this data to the wearer over audio in an
            average of 8 seconds.
        </p>
    </div>
</div>